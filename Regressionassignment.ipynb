{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?"
      ],
      "metadata": {
        "id": "GkPKU_A5hKAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple linear regression is a statistical method used to model the relationship between two continuous variables:\n",
        "\n",
        "1.Independent variable (x): The predictor variable that is thought to influence the other variable.\n",
        "2.Dependent variable (y): The response variable that is being predicted or explained.\n",
        "The goal of simple linear regression is to find a linear equation that best describes the relationship between these two variables. This equation can then be used to predict the value of the dependent variable based on the value of the independent variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "WWIGziUuhS8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?"
      ],
      "metadata": {
        "id": "zpOQgOTBr2n3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple linear regression relies on several key assumptions to ensure the validity and reliability of its results. These assumptions are:\n",
        "\n",
        "1.Linearity: The relationship between the independent variable (x) and the dependent variable (y) is assumed to be linear. This means that the change in y is constant for every one-unit change in x.  \n",
        "\n",
        "2.Independence: The observations in the data are assumed to be independent of each other. This means that the value of one observation does not affect the value of any other observation.  \n",
        "\n",
        "3.Homoscedasticity: The variance of the errors (the difference between the predicted values and the actual values) is assumed to be constant across all levels of the independent variable. This means that the spread of the residuals is roughly the same for all values of x.  \n",
        "\n",
        "4.Normality: The errors are assumed to be normally distributed. This means that the distribution of the residuals is bell-shaped and symmetrical around zero.  \n",
        "\n",
        "5.No Multicollinearity: This assumption is relevant in multiple linear regression, where there are multiple independent variables. It assumes that the independent variables are not highly correlated with each other.  \n",
        "\n",
        "6.No Endogeneity: This assumption ensures that there is no relationship between the errors and the independent variables. In other words, the independent variables are not influenced by the error term.  \n",
        "\n",
        "Violations of these assumptions can lead to inaccurate or misleading results.\n",
        "\n",
        " Therefore, it is important to check these assumptions before interpreting the results of a simple linear regression analysis."
      ],
      "metadata": {
        "id": "fEgPIM1_r99F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does the coefficient m represent in the equation Y=mX+c?"
      ],
      "metadata": {
        "id": "OHu738_v3oE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the equation Y = mX + c, the coefficient m represents the slope of the line.\n",
        "\n",
        "Here's what that means:\n",
        "\n",
        "Slope: The slope indicates the steepness and direction of the line.  It tells you how much the Y value changes for every one-unit increase in the X value.\n",
        "Positive Slope (m > 0):  As X increases, Y also increases. The line slants upwards from left to right.\n",
        "\n",
        "Negative Slope (m < 0): As X increases, Y decreases. The line slants downwards from left to right.\n",
        "\n",
        "Zero Slope (m = 0):  Y remains constant regardless of the X value. The line is horizontal."
      ],
      "metadata": {
        "id": "M4U05z0FJSW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does the intercept c represent in the equation Y=mX+c?"
      ],
      "metadata": {
        "id": "eaM06P6eJoEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the equation Y = mX + c, the intercept 'c' represents the value of Y when X is zero.\n",
        "c: The y-intercept (where the line crosses the Y-axis)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4WSNGrVtJyNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do we calculate the slope m in Simple Linear Regression"
      ],
      "metadata": {
        "id": "kzjeL19vKdXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slope (m) in simple linear regression represents the change in the dependent variable (y) for a one-unit change in the independent variable (x). It is also known as the regression coefficient.\n",
        "\n",
        "There are a couple of ways to calculate the slope:\n",
        "\n",
        "1. Using the formula:\n",
        "\n",
        "The most common way to calculate the slope is using the following formula:\n",
        "\n",
        "m = [n(Σxy) - (Σx)(Σy)] / [n(Σx^2) - (Σx)^2]\n",
        "Where:\n",
        "\n",
        "n is the number of data points\n",
        "Σxy is the sum of the product of x and y for each data point\n",
        "Σx is the sum of the x values\n",
        "Σy is the sum of the y values  \n",
        "Σx^2 is the sum of the squared x values\n",
        "2. Using statistical software:\n",
        "\n",
        "Most statistical software packages, such as R, Python (with libraries like Statsmodels or scikit-learn), and Excel, can calculate the slope for us. we simply need to input the data and run the regression analysis. The output will typically include the slope estimate along with other relevant statistics"
      ],
      "metadata": {
        "id": "b2XPgKM6n74a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the purpose of the least squares method in Simple Linear Regression?"
      ],
      "metadata": {
        "id": "7t3urqHWoupC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The least squares method is a fundamental technique used in simple linear regression to find the best-fitting line through a set of data points. Its primary purpose is to minimize the sum of the squared differences between the observed values (actual data points) and the predicted values (values on the regression line)."
      ],
      "metadata": {
        "id": "3D3s5X26o1ZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?"
      ],
      "metadata": {
        "id": "Obj1IDZ1rTNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How is the coefficient of determination (R²) interpreted in Simple Linear Regression\n",
        "\n",
        "\n",
        "The coefficient of determination, denoted as R², is a crucial statistical measure in simple linear regression. It represents the proportion of the variance in the dependent variable (y) that is explained by the independent variable (x). In other words, it quantifies how well the regression line fits the observed data.  \n",
        "\n",
        "Interpretation:\n",
        "\n",
        "R² values range from 0 to 1, and are often expressed as percentages. Here's how to interpret different R² values:\n",
        "\n",
        "R² = 0: This indicates that the independent variable does not explain any of the variation in the dependent variable. The regression line is essentially a horizontal line, and the model has no predictive power.  \n",
        "R² = 1: This indicates that the independent variable perfectly explains all the variation in the dependent variable. All the data points fall exactly on the regression line, and the model has perfect predictive power.  \n",
        "0 < R² < 1: This is the most common scenario. It indicates that the independent variable explains some, but not all, of the variation in the dependent variable. The closer R² is to 1, the better the model fits the data and the stronger the relationship between the variables.  \n",
        "Example:\n",
        "\n",
        "If a simple linear regression model has an R² of 0.75, it means that 75% of the variation in the dependent variable is explained by the independent variable. The remaining 25% of the variation is due to other factors not included in the model, such as random error or other variables."
      ],
      "metadata": {
        "id": "oe02N5Oerbi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "OYIkwFYnrxBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple linear regression is a statistical technique used to model the relationship between a dependent variable and two or more independent variables. It's an extension of simple linear regression, which can only handle one independent variable.\n",
        "\n",
        "The equation for a multiple linear regression model is:\n",
        "\n",
        "y = β0 + β1x1 + β2x2 + ... + βnxn + ε\n",
        "Where:\n",
        "\n",
        "y is the predicted value of the dependent variable  \n",
        "β0 is the y-intercept (the value of y when all independent variables are 0)  \n",
        "β1, β2, ..., βn are the regression coefficients for each independent variable, representing the change in y for a one-unit change in the corresponding independent variable, holding other variables constant.  \n",
        "x1, x2, ..., xn are the values of the independent variables"
      ],
      "metadata": {
        "id": "XcERWWn_r3gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main difference between Simple and Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "LF7w04tAzPYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference between simple and multiple linear regression lies in the number of independent variables used to predict the dependent variable.\n",
        "\n",
        "Simple Linear Regression: Uses only one independent variable to predict the dependent variable. It explores the relationship between two continuous variables.  \n",
        "Multiple Linear Regression: Uses two or more independent variables to predict the dependent variable.\n",
        "\n",
        " It allows you to model more complex relationships where multiple factors might influence the outcome."
      ],
      "metadata": {
        "id": "QVdZrHt1zYpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the key assumptions of Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "DVGs2E4a1QJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Multiple linear regression, like its simpler counterpart, relies on several crucial assumptions that need to be met for the model to be valid and reliable. These assumptions are:  \n",
        "\n",
        "1.Linearity: The relationship between the dependent variable and each independent variable is assumed to be linear. This means that the effect of a one-unit change in an independent variable on the dependent variable is constant, regardless of the value of the independent variable.  \n",
        "\n",
        "2.Independence: The observations in the dataset are assumed to be independent of each other. In other words, the value of one observation does not affect the value of any other observation. This is important to ensure that the errors in the model are not correlated.  \n",
        "\n",
        "3.Homoscedasticity: The variance of the errors (the difference between the predicted values and the actual values) is assumed to be constant across all levels of the independent variables. This means that the spread of the residuals is roughly the same for all values of the independent variables.  \n",
        "\n",
        "4.Normality: The errors are assumed to be normally distributed. This means that the distribution of the residuals is bell-shaped and symmetrical around zero. This assumption is important for conducting hypothesis tests and constructing confidence intervals.  \n",
        "\n",
        "5.No Multicollinearity: The independent variables are assumed to not be highly correlated with each other. Multicollinearity can make it difficult to determine the individual effect of each independent variable on the dependent variable, and it can also lead to unstable estimates of the regression coefficients.  \n",
        "\n",
        "6.No Endogeneity: This assumption ensures that there is no relationship between the errors and the independent variables.\n",
        "\n",
        " In other words, the independent variables are not influenced by the error term. If endogeneity exists, it can lead to biased estimates of the regression coefficients."
      ],
      "metadata": {
        "id": "oPDuXkGZ1Xbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?"
      ],
      "metadata": {
        "id": "h-GI26yt2D1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity refers to a situation where the variability of the residuals (errors) in a regression model is not constant across all levels of the independent variables. In simpler terms, the spread of the residuals is uneven, with some ranges of the independent variables having larger or smaller residuals than others. This violates one of the key assumptions of multiple linear regression, which is homoscedasticity (constant variance of errors).\n",
        "\n",
        "How Heteroscedasticity Affects Multiple Linear Regression Results:\n",
        "\n",
        "1.Inefficient Estimates: Heteroscedasticity leads to inefficient estimates of the regression coefficients. This means that the estimated coefficients are not as precise as they could be if the errors were homoscedastic. As a result, the confidence intervals for the coefficients will be wider, making it harder to draw reliable conclusions about the significance of the relationships between the variables.\n",
        "\n",
        "2.Biased Standard Errors: Heteroscedasticity can also bias the standard errors of the regression coefficients. This means that the standard errors are either underestimated or overestimated, leading to incorrect t-statistics and p-values. This can lead to incorrect conclusions about the statistical significance of the independent variables.\n",
        "\n",
        "3.Invalid Hypothesis Tests: When heteroscedasticity is present, the usual hypothesis tests for the regression coefficients, such as the t-test and F-test, may not be valid. This is because these tests rely on the assumption of homoscedasticity. Using these tests when heteroscedasticity is present can lead to incorrect inferences about the relationships between the variables.\n",
        "\n",
        "4.Unreliable Predictions: Heteroscedasticity can also affect the reliability of predictions made using the regression model. When the spread of the residuals is uneven, the model may be less accurate in predicting values for certain ranges of the independent variables."
      ],
      "metadata": {
        "id": "Zp46Ks3H2KVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.How can you improve a Multiple Linear Regression model with high multicollinearity"
      ],
      "metadata": {
        "id": "ZDz4aqeN2gHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High multicollinearity in a multiple linear regression model can lead to several issues, such as inflated standard errors, unstable coefficients, and difficulty in interpreting the individual effects of predictors. Here are some strategies to address this problem:  \n",
        "\n",
        "1. Identify and Remove Highly Correlated Predictors:\n",
        "\n",
        "Calculate Variance Inflation Factors (VIFs): VIFs measure how much the variance of an estimated regression coefficient is increased due to multicollinearity. A VIF of 1 indicates no correlation, while values above 5 or 10 suggest problematic multicollinearity.  \n",
        "Remove one of the correlated predictors: If two or more predictors have high VIFs, consider removing one of them. Choose the predictor that is less theoretically important or has less practical significance.\n",
        "Iterate and reassess: After removing a predictor, recalculate VIFs and check if multicollinearity has been reduced.\n",
        "2. Combine Correlated Variables:\n",
        "\n",
        "Create a composite variable: If highly correlated predictors have a similar underlying concept, combine them into a single composite variable. This can be done by summing, averaging, or creating an index.  \n",
        "Principal Component Analysis (PCA): PCA is a dimensionality reduction technique that can create a smaller set of uncorrelated components from the original predictors. These components can be used in the regression model instead of the original predictors.  \n",
        "3. Use Regularization Techniques:\n",
        "\n",
        "Ridge Regression: Ridge regression adds a penalty to the size of the coefficients, shrinking them towards zero. This can help stabilize the estimates and reduce the impact of multicollinearity.  \n",
        "Lasso Regression: Lasso regression also shrinks coefficients but can force some coefficients to exactly zero, effectively performing variable selection. This can help identify the most important predictors and reduce multicollinearity.  \n",
        "4. Increase Sample Size:\n",
        "\n",
        "More data: Increasing the sample size can improve the precision of the estimates and reduce the impact of multicollinearity. However, this may not always be feasible.  \n",
        "5. Center the Data:\n",
        "\n",
        "Standardization: Centering the data by subtracting the mean from each predictor can sometimes reduce multicollinearity, especially if the predictors have different scales.\n",
        "6. Use a Different Model:\n",
        "\n",
        "Partial Least Squares Regression (PLS): PLS is a technique that can handle multicollinearity by creating a set of uncorrelated components from the original predictors.  \n",
        "Other models: If linearity is a concern, consider non-linear regression models or other machine learning algorithms that can handle non-linear relationships."
      ],
      "metadata": {
        "id": "eKcvGmRE2x2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are some common techniques for transforming categorical variables for use in regression models?"
      ],
      "metadata": {
        "id": "EiSXNuO-315Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical variables, which represent characteristics or groups, need to be transformed into numerical representations before they can be used in regression models. Here are some common techniques:  \n",
        "\n",
        "1. Dummy Coding:\n",
        "\n",
        "Creates binary (0 or 1) variables for each category.  \n",
        "For a categorical variable with 'k' categories, you create 'k-1' dummy variables.\n",
        "The omitted category becomes the reference category.  \n",
        "Example: If you have a variable \"Color\" with categories \"Red,\" \"Green,\" and \"Blue,\" you would create two dummy variables: \"Color_Red\" (1 if Red, 0 otherwise) and \"Color_Green\" (1 if Green, 0 otherwise). \"Blue\" would be the reference category.\n",
        "2. One-Hot Encoding:\n",
        "\n",
        "Similar to dummy coding, but creates 'k' binary variables for 'k' categories.  \n",
        "Each category gets its own binary variable.  \n",
        "Example: For the \"Color\" variable, you would create three variables: \"Color_Red,\" \"Color_Green,\" and \"Color_Blue.\"\n",
        "3. Effect Coding:\n",
        "\n",
        "Similar to dummy coding, but the reference category is coded as -1 instead of 0.  \n",
        "Useful when you want to compare the average effect of each category to the overall average.\n",
        "4. Label Encoding:\n",
        "\n",
        "Assigns a unique integer to each category.  \n",
        "Example: \"Red\" might be coded as 1, \"Green\" as 2, and \"Blue\" as 3.\n",
        "Caution: Can introduce artificial ordinality, implying an order between categories where none exists.\n",
        "5. Frequency Encoding:\n",
        "\n",
        "Replaces each category with its frequency (or percentage) in the dataset.  \n",
        "Captures information about the prevalence of each category.\n",
        "6. Target Encoding (Mean Encoding):\n",
        "\n",
        "Replaces each category with the average value of the target variable for that category.  \n",
        "Can be powerful but prone to overfitting, especially with small datasets."
      ],
      "metadata": {
        "id": "pokutKGp3_ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.What is the role of interaction terms in Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "6LAyTyebwoPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interaction terms in multiple linear regression play a crucial role in capturing the complex interplay between independent variables and their combined effect on the dependent variable.They allow us to model situations where the relationship between one independent variable and the dependent variable changes depending on the value of another independent variable."
      ],
      "metadata": {
        "id": "xLP4sObfxJUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  How can the interpretation of intercept differ between Simple and Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "UklF8CrIUPkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The interpretation of the intercept (β0) can differ significantly between simple and multiple linear regression due to the presence of multiple predictors in the latter.\n",
        "\n",
        "Simple Linear Regression:\n",
        "\n",
        "1. In simple linear regression, the intercept represents the predicted value of the dependent variable (y) when the independent variable (x) is zero.  \n",
        "It's the point where the regression line crosses the y-axis.  \n",
        "This interpretation is often straightforward and meaningful, especially when the value of x = 0 is within the range of observed data and has a practical interpretation.\n",
        "Multiple Linear Regression:\n",
        "\n",
        "2. In multiple linear regression, the intercept represents the predicted value of the dependent variable (y) when all independent variables (x1, x2, ..., xn) are zero.  \n",
        "This interpretation can be less meaningful or even nonsensical if the scenario where all independent variables are zero is not realistic or doesn't fall within the observed data range.\n",
        "For example, if independent variables represent age, height, and weight, it's impossible to have all of them be zero simultaneously."
      ],
      "metadata": {
        "id": "sdbPgs3jUU58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.What is the significance of the slope in regression analysis, and how does it affect predictions?"
      ],
      "metadata": {
        "id": "gzEmqs6yVGmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slope in regression analysis represents the magnitude and direction of the relationship between the independent variable(s) and the dependent variable. It quantifies how much the dependent variable is expected to change for a one-unit increase in the independent variable, assuming all other variables are held constant.  \n",
        "\n",
        "Significance of the slope:\n",
        "\n",
        "1.Indicates the strength of the relationship: A larger slope (in absolute value) suggests a stronger relationship between the variables, meaning that changes in the independent variable have a greater impact on the dependent variable.  \n",
        "2.Determines the direction of the relationship: A positive slope indicates a positive relationship, meaning that as the independent variable increases, the dependent variable also tends to increase. Conversely, a negative slope indicates a negative relationship, where the dependent variable tends to decrease as the independent variable increases.  \n",
        "3.Helps in making predictions: The slope is a crucial component of the regression equation used for predictions. By plugging in different values for the independent variable, you can estimate the corresponding values of the dependent variable.\n",
        "How the slope affects predictions:\n",
        "\n",
        "1.Accuracy of predictions: The accuracy of predictions depends heavily on the accuracy of the estimated slope. If the slope is accurately estimated, the predictions are likely to be more reliable.\n",
        "2.Sensitivity to changes in the independent variable: The slope determines how sensitive the predictions are to changes in the independent variable. A larger slope means that even small changes in the independent variable can lead to substantial changes in the predicted value of the dependent variable.\n",
        "3.Extrapolation: Extrapolating predictions beyond the range of the observed data can be risky, especially if the relationship between the variables is not truly linear. The slope can amplify the uncertainty in predictions when extrapolating"
      ],
      "metadata": {
        "id": "V1Qmrb0xVOhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How does the intercept in a regression model provide context for the relationship between variables?"
      ],
      "metadata": {
        "id": "S7VvFdSrV8Md"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intercept in a regression model provides context by giving a baseline value for the dependent variable when all independent variables are zero.It helps us understand the starting point of the relationship and how much the dependent variable is influenced by factors not included in the model."
      ],
      "metadata": {
        "id": "6m4bkGnWWN1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the limitations of using R² as a sole measure of model performance"
      ],
      "metadata": {
        "id": "DHqrZBAVWLkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While R² is a popular metric for evaluating regression models, relying solely on it can be misleading. Here are some limitations:  \n",
        "\n",
        "1.R² always increases with more predictors: Adding more independent variables to a model will almost always increase R², even if those variables are not truly related to the dependent variable. This can lead to overfitting, where the model performs well on the training data but poorly on new, unseen data.  \n",
        "2.R² doesn't tell you if the model is biased: A high R² doesn't necessarily mean the model is a good fit for the data. It might be capturing the overall trend but missing important nuances or having systematic errors.  \n",
        "3.R² doesn't account for model complexity: A simple model with a lower R² might be preferable to a complex model with a higher R² if it's easier to interpret and less prone to overfitting.\n",
        "4.R² is sensitive to outliers: Outliers can disproportionately influence R², making it seem like the model is performing better or worse than it actually is.  \n",
        "5.R² doesn't indicate the appropriateness of the model: A high R² doesn't guarantee that the model is appropriate for the data.\n",
        "It's crucial to check other assumptions, like linearity, homoscedasticity, and normality of residuals."
      ],
      "metadata": {
        "id": "unv8GDrnlSDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How would you interpret a large standard error for a regression coefficient?"
      ],
      "metadata": {
        "id": "THmnglWSlth6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A large standard error for a regression coefficient indicates that there is a lot of uncertainty or variability in the estimate of that coefficient. This means that the model is less certain about the true relationship between the predictor variable and the outcome variable.\n",
        "\n",
        "Here's a breakdown of what a large standard error might suggest and how to interpret it:\n",
        "\n",
        "Possible implications:\n",
        "\n",
        "1.Weak relationship: The predictor variable may have a weak relationship with the outcome variable. The data doesn't provide strong evidence for a clear effect.\n",
        "2.Insufficient data: There might not be enough data points to accurately estimate the coefficient. More data could potentially lead to a more precise estimate.\n",
        "3.High variability in the data: The data for the predictor variable might be widely spread out, making it harder to pinpoint its exact effect on the outcome.\n",
        "4.Multicollinearity: This occurs when predictor variables are highly correlated with each other. It can inflate standard errors, making it difficult to isolate the individual effect of each predictor.  \n",
        "How to interpret it:\n",
        "\n",
        "1.Less confidence in the estimate: A large standard error means we are less confident that the estimated coefficient is close to the true value. The true effect of the predictor could be much larger or smaller than the estimate.\n",
        "2.Wider confidence intervals: The confidence interval for the coefficient will be wider, reflecting the increased uncertainty.\n",
        "3.Reduced statistical significance: The coefficient might be statistically insignificant, meaning we cannot confidently conclude that it has a non-zero effect on the outcome."
      ],
      "metadata": {
        "id": "MbZmAHYNl02C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?"
      ],
      "metadata": {
        "id": "4DcF5Hjynr2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity, the unequal variance of errors across the range of predictor values, can be identified in residual plots by looking for patterns that indicate non-constant variance. Here's how:  \n",
        "\n",
        "1.Funnel Shape: The most common pattern is a funnel shape, where the spread of residuals increases or decreases as the predicted values change. This indicates that the model's accuracy varies across the range of predictions.  \n",
        "2.Fan Shape: Another pattern is a fan shape, where the spread of residuals increases as the predicted values increase. This suggests that the model is less accurate at higher predicted values.  \n",
        "3.Clusters: Clusters of residuals with different variances can also indicate heteroscedasticity. This might suggest that there are subgroups in the data with different error variances.\n",
        "4.No Pattern: In some cases, there might be no clear pattern in the residual plot, but the overall spread of residuals may be uneven. This can still indicate heteroscedasticity.\n",
        "It's important to address heteroscedasticity because it violates the assumptions of linear regression, leading to:\n",
        "\n",
        "1.Inefficient Estimates: Heteroscedasticity makes the ordinary least squares (OLS) estimates less efficient, meaning they don't have the minimum variance. This can lead to wider confidence intervals and less reliable hypothesis tests.  \n",
        "2.Biased Standard Errors: Heteroscedasticity can bias the standard errors of the regression coefficients, leading to incorrect conclusions about the significance of the predictors.  \n",
        "3.Misleading p-values: Biased standard errors can result in inaccurate p-values, potentially leading to Type I or Type II errors in hypothesis testing.\n",
        "4.Invalid Confidence Intervals: Heteroscedasticity can invalidate the confidence intervals for the regression coefficients, making them unreliable for inference.\n",
        "Addressing heteroscedasticity often involves transforming the data or using weighted least squares regression, which gives different weights to different observations based on their variance.\n",
        "\n",
        " By addressing heteroscedasticity, we can obtain more accurate and reliable estimates of the relationships between variables."
      ],
      "metadata": {
        "id": "FzvQG-g9n289"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?"
      ],
      "metadata": {
        "id": "Zys8BS-EsoFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This situation typically indicates that your model has too many predictor variables that don't contribute significantly to explaining the variance in the dependent variable. Here's why:\n",
        "\n",
        "R²:  R-squared measures the proportion of variance in the dependent variable explained by all independent variables in the model. Adding more predictors, even irrelevant ones, will almost always increase R². It doesn't penalize for complexity.  \n",
        "\n",
        "Adjusted R²: Adjusted R-squared accounts for the number of predictors in the model. It penalizes the addition of variables that don't improve the model's explanatory power significantly. It provides a more realistic assessment of the model's goodness-of-fit, especially when comparing models with different numbers of predictors.  \n",
        "\n",
        "So, a high R² but low adjusted R² suggests:\n",
        "\n",
        "1.Overfitting: Your model might be too complex and is fitting the noise in the training data rather than the underlying relationship. This can lead to poor generalization to new data.\n",
        "2.Unnecessary predictors: Some variables in your model might not be contributing meaningfully to predicting the outcome and are just inflating the R² value."
      ],
      "metadata": {
        "id": "P1_RESsssura"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.Why is it important to scale variables in Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "0Aad5Z_ts8jJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling variables in Multiple Linear Regression can be important for several reasons, though it's not always strictly necessary. Here's a breakdown of why and when it matters:\n",
        "\n",
        "1. Improved Interpretation of Coefficients:\n",
        "\n",
        "Different Units: When your predictor variables have different units (e.g., age in years, income in dollars, weight in kilograms), the magnitude of their coefficients isn't directly comparable. Scaling them to a standard range (like 0 to 1 or -1 to 1) allows you to compare the relative importance of each predictor. Larger coefficients after scaling indicate stronger effects.\n",
        "Standardization: Standardizing variables (z-score normalization) centers them around a mean of 0 with a standard deviation of 1. This makes the coefficients represent the change in the dependent variable for a one standard deviation change in the predictor, facilitating comparisons.  \n",
        "2. Algorithm Performance:\n",
        "\n",
        "Gradient Descent: Algorithms like gradient descent, used to estimate coefficients, can converge faster when variables are scaled. This is because features with larger scales can dominate the optimization process.  \n",
        "Regularization: Regularization techniques like LASSO and Ridge regression, which penalize large coefficients, are sensitive to the scale of variables. Scaling ensures that all variables are penalized equally.  \n",
        "3. Avoiding Numerical Instability:\n",
        "\n",
        "Large Values: Very large or very small values in some variables can sometimes cause numerical instability in calculations. Scaling can help mitigate this."
      ],
      "metadata": {
        "id": "8C2TnouttBf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.What is polynomial regression?"
      ],
      "metadata": {
        "id": "nWwqs5dTt7o_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x.  \n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "Why use polynomial regression?\n",
        "\n",
        "Capturing Non-linearity:  While linear regression assumes a straight-line relationship between variables, polynomial regression can model curved relationships. This is useful when the data shows a clear non-linear pattern.  \n",
        "\n",
        "Flexibility: By increasing the degree of the polynomial (e.g., quadratic, cubic), you can create more complex curves to fit the data more closely.  \n",
        "\n",
        "How it works:\n",
        "\n",
        "Adding Polynomial Terms:  Instead of just using x as the predictor, polynomial regression adds powers of x as new predictors.\n",
        "\n",
        "For example, a quadratic model would include x, x^2, a cubic model would include  x, x^2, x^3, and so on.\n",
        "Equation: The general equation for a polynomial regression model is:\n",
        "\n",
        "  y=b0+b1x+b2x^2</6>+...+bn x^n +e\n",
        "  where:\n",
        "* y is the dependent variable\n",
        "* x is the independent variable\n",
        "* b0,b1,...,bn are the coefficients\n",
        "* n is the degree of the polynomial\n",
        "* e is the error term"
      ],
      "metadata": {
        "id": "TUYSPkgwvjaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How does polynomial regression differ from linear regression?"
      ],
      "metadata": {
        "id": "shS2-gStziWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While both polynomial regression and linear regression are regression techniques used to model the relationship between a dependent variable and one or more independent variables, they differ in how they capture the relationship:  \n",
        "\n",
        "Linear Regression:\n",
        "Linear Relationship: Assumes a linear relationship between the variables, meaning the change in the dependent variable is constant for a unit change in the independent variable.  \n",
        "Equation: The equation is of the form y = b0 + b1x1 + b2x2 + ... + bn*xn, where y is the dependent variable, x1, x2, ... xn are the independent variables, b0 is the intercept, and b1, b2, ... bn are the coefficients.\n",
        "Straight Line: When plotted, the relationship between the variables is represented by a straight line.  \n",
        "Polynomial Regression:\n",
        "Non-linear Relationship: Models non-linear relationships between the variables, allowing for curves and bends in the relationship.  \n",
        "Equation: Introduces polynomial terms (powers of the independent variables) into the equation, such as y = b0 + b1x + b2x^2 + b3x^3 + ....\n",
        "Curves: When plotted, the relationship between the variables is represented by a curve, capturing more complex patterns in the data."
      ],
      "metadata": {
        "id": "-FxWjVsIzrGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?"
      ],
      "metadata": {
        "id": "Vy7OgNu-3XmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression is used when the relationship between the dependent and independent variables is non-linear. It is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x.\n",
        "\n",
        "Here are some examples of when polynomial regression might be used:\n",
        "\n",
        "1.Growth rate of tissues: A researcher might use polynomial regression to model the growth rate of a particular type of tissue in an organism.  \n",
        "2.Trajectory of a projectile: Polynomial regression could be used to model the trajectory of a projectile, such as a rocket or a ball.  \n",
        "3.Sales trend over time: A business analyst might use polynomial regression to model the sales trend of a particular product over time.\n",
        "Polynomial regression is a powerful tool that can be used to model complex non-linear relationships.\n",
        "\n",
        "However, it is important to use it carefully, as overfitting can occur if the degree of the polynomial is too high."
      ],
      "metadata": {
        "id": "bCL4m96Q3cdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. What is the general equation for polynomial regression?"
      ],
      "metadata": {
        "id": "MeslcCah3xYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y=b0+b1x+b2x^2</6>+...+bn x^n +e where:\n",
        "\n",
        "y is the dependent variable\n",
        "x is the independent variable\n",
        "b0,b1,...,bn are the coefficients\n",
        "n is the degree of the polynomial\n",
        "e is the error term"
      ],
      "metadata": {
        "id": "KvCr8dth33QL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27.Can polynomial regression be applied to multiple variables?\n"
      ],
      "metadata": {
        "id": "VYa8GYXy47QV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression can be applied to multiple variables. It's not limited to just one independent variable.  \n",
        "\n",
        "Here's how it works with multiple variables:\n",
        "\n",
        "1.  Multiple Linear Regression as the Foundation:\n",
        "\n",
        "Think of multiple linear regression, where you have an equation like: y = b0 + b1x1 + b2x2 + ... + bnxn.\n",
        "2. Introducing Polynomial Terms:\n",
        "\n",
        "Now, you can add polynomial terms for each of those independent variables (x1, x2, etc.).\n",
        "For example, you could include x1^2, x2^3, or even interaction terms like x1 * x2."
      ],
      "metadata": {
        "id": "5S_w3ZI85AqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28.What are the limitations of polynomial regression?"
      ],
      "metadata": {
        "id": "V0oyjud_5Ut6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While polynomial regression offers a powerful way to model non-linear relationships, it's not without limitations. Here are some key drawbacks to consider:  \n",
        "\n",
        "1. Overfitting:\n",
        "\n",
        "High Degree Polynomials: A high-degree polynomial (e.g., x^5, x^6, etc.) can create a very complex curve that fits the training data extremely well, including the noise. This leads to overfitting, where the model performs poorly on new, unseen data.\n",
        "Poor Generalization: An overfit model doesn't generalize well to new data, making it unreliable for prediction and inference.  \n",
        "2. Interpretability:\n",
        "\n",
        "Complex Coefficients: Interpreting the coefficients in polynomial regression, especially with higher-degree terms and interactions, can be challenging. It becomes difficult to explain the relationship between the variables in a meaningful way.  \n",
        "3. Outliers:\n",
        "\n",
        "Sensitivity to Outliers: Outliers can have a significant influence on the shape of the polynomial curve, potentially leading to a model that doesn't accurately represent the underlying relationship.\n",
        "4. Extrapolation:\n",
        "\n",
        "Poor Extrapolation: Polynomial regression models can be unreliable for extrapolating beyond the range of the observed data. The curve can behave unexpectedly outside the data range, leading to inaccurate predictions.\n",
        "5. Multicollinearity:\n",
        "\n",
        "High Correlation: Introducing polynomial terms can create high multicollinearity (correlation between predictor variables). This can make it difficult to isolate the individual effects of the variables and lead to unstable estimates.  \n",
        "6. Computational Cost:\n",
        "\n",
        "Increased Complexity: Higher-degree polynomials and multiple variables can increase the computational cost of fitting the model.\n",
        "7. Model Selection:\n",
        "\n",
        "Choosing the Degree: Selecting the appropriate degree of the polynomial can be challenging. There's a trade-off between model complexity and fit"
      ],
      "metadata": {
        "id": "OlMYfrdm5aZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?"
      ],
      "metadata": {
        "id": "YrSXX5PB5s6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "electing the optimal degree for a polynomial regression model is crucial to balance its complexity and its ability to accurately capture the underlying relationship in the data. Here are several methods commonly used to evaluate model fit and choose the best degree:  \n",
        "\n",
        "1.  Resampling Techniques:\n",
        "\n",
        "k-Fold Cross-Validation: Divide the data into k folds (subsets). Train the model on k-1 folds and test it on the remaining fold. Repeat this process k times, using a different fold for testing each time. Calculate the average prediction error across all folds for each degree of the polynomial. Choose the degree with the lowest average prediction error.  \n",
        "Leave-One-Out Cross-Validation (LOOCV): A special case of k-fold cross-validation where k equals the number of data points. The model is trained on all but one data point and tested on the left-out point. This is repeated for each data point.  \n",
        "2. Information Criteria:\n",
        "\n",
        "Akaike Information Criterion (AIC): Estimates the prediction error for a statistical model relative to other statistical models trained on the same data. Lower AIC values indicate a better fit. It penalizes models with more parameters (higher degree polynomials) to prevent overfitting.  \n",
        "Bayesian Information Criterion (BIC): Similar to AIC, but imposes a stronger penalty for model complexity. It tends to favor simpler models compared to AIC.  \n",
        "3. R-squared and Adjusted R-squared:\n",
        "\n",
        "R-squared: Measures the proportion of variance in the dependent variable explained by the model. While it generally increases with the degree of the polynomial, it doesn't account for model complexity.\n",
        "Adjusted R-squared: A modified version of R-squared that adjusts for the number of predictors in the model. It penalizes the addition of unnecessary variables and provides a more realistic assessment of model fit. Look for the degree where adjusted R-squared is maximized.  \n",
        "4. Visual Assessment:\n",
        "\n",
        "Residual Plots: Plot the residuals (the difference between predicted and actual values) against the predicted values. Look for patterns in the residuals. A good fit should have residuals randomly scattered around zero with no clear trends.  \n",
        "Fitted Curve vs. Data: Visually compare the fitted polynomial curve to the scatter plot of the data. Assess how well the curve captures the overall trend and avoids overfitting the noise."
      ],
      "metadata": {
        "id": "r4ZHdiXF6Ax_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Why is visualization important in polynomial regression?"
      ],
      "metadata": {
        "id": "iJXCUQnY6E_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization plays a crucial role in polynomial regression analysis. It helps you gain insights into the data, assess the model's fit, and diagnose potential problems. Here's why visualization is important:\n",
        "\n",
        "Understanding the Data:\n",
        "1.Scatter Plots: Before fitting any model, visualize the relationship between the variables using scatter plots. This helps you identify potential non-linear patterns and decide whether polynomial regression is appropriate.\n",
        "2.Trends and Outliers: Scatter plots reveal trends, clusters, and potential outliers in the data. This information can guide your choice of polynomial degree and help you address outliers that might unduly influence the model.  \n",
        "Assessing Model Fit:\n",
        "3.Fitted Curve vs. Data: Plot the fitted polynomial curve against the scatter plot of the data. This visualization allows you to see how well the curve captures the overall trend and whether it overfits the noise.\n",
        "4.Residual Plots: Analyze residual plots to assess the model's assumptions. Look for patterns in the residuals that might indicate heteroscedasticity (non-constant variance) or non-linearity that the model has not captured.  \n",
        "Diagnosing Problems:\n",
        "1.Overfitting: Visualizing the fitted curve can help you identify overfitting, where the curve follows the training data too closely and might not generalize well to new data.\n",
        "2.Underfitting: If the curve is too simple and misses the underlying trend, it indicates underfitting. Visualization helps you recognize the need for a higher-degree polynomial.  \n",
        "3.Outlier Influence: Visualize how outliers affect the shape of the curve. This can help you decide whether to remove or transform outliers or use robust regression techniques.  \n",
        "4.Communicating Results:\n",
        "Clear and Intuitive: Visualizations provide a clear and intuitive way to communicate the results of the analysis to both technical and non-technical audiences.\n",
        "5.Insights and Patterns: Visualizations can highlight interesting insights and patterns in the data that might not be apparent from the numerical output alone.\n",
        "\n"
      ],
      "metadata": {
        "id": "wnhjh3rQ6Tcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. How is polynomial regression implemented in Python\n"
      ],
      "metadata": {
        "id": "vg2BC2IM6pTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Step 1: Generate synthetic dataset\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 3 * X**2 + 5 * X + np.random.randn(100, 1) * 10\n",
        "\n",
        "# Step 2: Transform input features into polynomial features\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "# Step 3: Train linear regression on transformed features\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_poly)\n",
        "\n",
        "# Step 5: Visualize results\n",
        "plt.scatter(X, y, color='blue', label=\"Actual Data\")\n",
        "plt.plot(np.sort(X[:,0]), np.sort(y_pred[:,0]), color='red', label=\"Model Prediction\")\n",
        "plt.title(\"Polynomial Regression Results\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Evaluate performance\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "r_squared = model.score(X_poly,y )\n",
        "print(f\"MSE : {mse:.4f}, R-Squared : {r_squared:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "CJ-ky8AA62Im",
        "outputId": "5b3f8d5a-3b94-4d05-9c35-ac884b78febf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 97.3558, R-Squared : 0.9904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xFESgEAX63eg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}